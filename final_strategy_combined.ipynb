{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75461da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Window: 2025-11-24 to 2026-02-22\n",
      "\n",
      ">>> Extracting Data & Labeling Targets for EURUSD...\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "incompatible merge keys [0] dtype('<M8[s]') and dtype('<M8[us]'), must be the same type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 241\u001b[0m\n\u001b[0;32m    238\u001b[0m     mt5\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 241\u001b[0m     auto_train_pipeline()\n",
      "Cell \u001b[1;32mIn[2], line 208\u001b[0m, in \u001b[0;36mauto_train_pipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m    205\u001b[0m         dxy_df \u001b[38;5;241m=\u001b[39m dxy_raw[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdxy_rsi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdxy_ema_dist\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m SYMBOLS:\n\u001b[1;32m--> 208\u001b[0m     df \u001b[38;5;241m=\u001b[39m build_features_and_labels(sym, dxy_df, utc_from, utc_to)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m50\u001b[39m: \n\u001b[0;32m    210\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msym\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, not enough data.\u001b[39m\u001b[38;5;124m\"\u001b[39m); \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 78\u001b[0m, in \u001b[0;36mbuild_features_and_labels\u001b[1;34m(symbol_name, dxy_df, utc_from, utc_to)\u001b[0m\n\u001b[0;32m     75\u001b[0m df_m15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_m15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     76\u001b[0m h4_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m h4_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 78\u001b[0m df_m15 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge_asof(df_m15\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m), h4_context\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m), on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dxy_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     dxy_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dxy_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:917\u001b[0m, in \u001b[0;36mmerge_asof\u001b[1;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_asof\u001b[39m(\n\u001b[0;32m    658\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    671\u001b[0m     direction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    672\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03m    Perform a merge by key distance.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m     op \u001b[38;5;241m=\u001b[39m _AsOfMerge(\n\u001b[0;32m    918\u001b[0m         left,\n\u001b[0;32m    919\u001b[0m         right,\n\u001b[0;32m    920\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    921\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    922\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    923\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    924\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    925\u001b[0m         by\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m    926\u001b[0m         left_by\u001b[38;5;241m=\u001b[39mleft_by,\n\u001b[0;32m    927\u001b[0m         right_by\u001b[38;5;241m=\u001b[39mright_by,\n\u001b[0;32m    928\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    929\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    930\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[0;32m    931\u001b[0m         allow_exact_matches\u001b[38;5;241m=\u001b[39mallow_exact_matches,\n\u001b[0;32m    932\u001b[0m         direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[0;32m    933\u001b[0m     )\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2353\u001b[0m, in \u001b[0;36m_AsOfMerge.__init__\u001b[1;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m   2347\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_exact_matches must be boolean, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2349\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_exact_matches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2350\u001b[0m     )\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m-> 2353\u001b[0m _OrderedMerge\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2355\u001b[0m     left,\n\u001b[0;32m   2356\u001b[0m     right,\n\u001b[0;32m   2357\u001b[0m     on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m   2358\u001b[0m     left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m   2359\u001b[0m     right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m   2360\u001b[0m     left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m   2361\u001b[0m     right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m   2362\u001b[0m     how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m   2363\u001b[0m     suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m   2364\u001b[0m     fill_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2365\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2265\u001b[0m, in \u001b[0;36m_OrderedMerge.__init__\u001b[1;34m(self, left, right, on, left_on, right_on, left_index, right_index, suffixes, fill_method, how)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   2252\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2253\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2262\u001b[0m     how: JoinHow \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2263\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_method \u001b[38;5;241m=\u001b[39m fill_method\n\u001b[1;32m-> 2265\u001b[0m     _MergeOperation\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   2266\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2267\u001b[0m         left,\n\u001b[0;32m   2268\u001b[0m         right,\n\u001b[0;32m   2269\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m   2270\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m   2271\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m   2272\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m   2273\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m   2274\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m   2275\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m   2276\u001b[0m         sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# factorize sorts\u001b[39;00m\n\u001b[0;32m   2277\u001b[0m     )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1026\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right_drop:\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_drop_labels_or_levels(right_drop)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_require_matching_dtypes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys)\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2478\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes\u001b[1;34m(self, left_join_keys, right_join_keys)\u001b[0m\n\u001b[0;32m   2476\u001b[0m \u001b[38;5;66;03m# validate index types are the same\u001b[39;00m\n\u001b[0;32m   2477\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (lk, rk) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(left_join_keys, right_join_keys, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m-> 2478\u001b[0m     _check_dtype_match(lk, rk, i)\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_index:\n\u001b[0;32m   2481\u001b[0m     lt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_values\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2474\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes.<locals>._check_dtype_match\u001b[1;34m(left, right, i)\u001b[0m\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2470\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2471\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible merge keys [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mright\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, must be the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2473\u001b[0m     )\n\u001b[1;32m-> 2474\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n",
      "\u001b[1;31mMergeError\u001b[0m: incompatible merge keys [0] dtype('<M8[s]') and dtype('<M8[us]'), must be the same type"
     ]
    }
   ],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "import pandas_ta as ta\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "# ONNX Imports\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes, calculate_linear_regressor_output_shapes\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "\n",
    "# --- REGISTER XGBOOST CONVERTERS ---\n",
    "update_registered_converter(\n",
    "    xgb.XGBClassifier, \"XGBoostXGBClassifier\",\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={\"nocl\": [True, False], \"zipmap\": [True, False, \"renamed\"]}\n",
    ")\n",
    "update_registered_converter(\n",
    "    xgb.XGBRegressor, \"XGBoostXGBRegressor\",\n",
    "    calculate_linear_regressor_output_shapes, convert_xgboost\n",
    ")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SYMBOLS = [\"EURUSD\", \"GBPUSD\", \"USDJPY\"] # Add more as needed\n",
    "DXY_SYMBOL = \"DXY\"\n",
    "EMA_PERIOD = 50\n",
    "SL_PIPS = 15.0\n",
    "RR_RATIO = 2.0\n",
    "TIMEOUT_BARS = 48\n",
    "INVALIDATION_PIPS = 15.0\n",
    "WINDOW_DAYS = 90 # Rolling window for Concept Drift\n",
    "\n",
    "def fetch_data(symbol, timeframe, utc_from, utc_to):\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, utc_from, utc_to)\n",
    "    if rates is None or len(rates) == 0: return None\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "    return df\n",
    "\n",
    "def build_features_and_labels(symbol_name, dxy_df, utc_from, utc_to):\n",
    "    print(f\"\\n>>> Extracting Data & Labeling Targets for {symbol_name}...\")\n",
    "    \n",
    "    symbols_found = mt5.symbols_get(f\"*{symbol_name}*\")\n",
    "    if not symbols_found: return None\n",
    "    actual_symbol = symbols_found[0].name\n",
    "    \n",
    "    df_m15 = fetch_data(actual_symbol, mt5.TIMEFRAME_M15, utc_from, utc_to)\n",
    "    df_h4 = fetch_data(actual_symbol, mt5.TIMEFRAME_H4, utc_from, utc_to)\n",
    "    if df_m15 is None or df_h4 is None: return None\n",
    "\n",
    "    info = mt5.symbol_info(actual_symbol)\n",
    "    pip_val = info.point * (10.0 if info.digits in [3, 5] else 1.0)\n",
    "\n",
    "    # 1. H4 Context\n",
    "    df_h4['h4_ema_50'] = df_h4['close'].ewm(span=EMA_PERIOD, adjust=False).mean()\n",
    "    df_h4['h4_dist_to_ema'] = (df_h4['close'] - df_h4['h4_ema_50']) / pip_val\n",
    "    df_h4['h4_rsi_14'] = ta.rsi(df_h4['close'], length=14)\n",
    "    df_h4 = df_h4.dropna(subset=['h4_rsi_14', 'h4_dist_to_ema']).copy()\n",
    "    df_h4['time_aligned'] = df_h4['time'] + pd.Timedelta(hours=4)\n",
    "    h4_context = df_h4[['time_aligned', 'h4_dist_to_ema', 'h4_rsi_14']].rename(columns={'time_aligned': 'time'})\n",
    "\n",
    "    # 2. M15 Features\n",
    "    df_m15['ema_50'] = df_m15['close'].ewm(span=EMA_PERIOD, adjust=False).mean()\n",
    "    df_m15['dist_to_ema'] = (df_m15['close'] - df_m15['ema_50']) / pip_val\n",
    "    df_m15['hour_of_day'] = df_m15['time'].dt.hour\n",
    "    df_m15['atr_14'] = ta.atr(df_m15['high'], df_m15['low'], df_m15['close'], length=14)\n",
    "    df_m15['rsi_14'] = ta.rsi(df_m15['close'], length=14)\n",
    "    \n",
    "    # 3. Stitch Tensors (FIXED: Timezone stripping AND exact resolution matching)\n",
    "    df_m15['time'] = df_m15['time'].dt.tz_localize(None).astype('datetime64[ns]')\n",
    "    h4_context['time'] = h4_context['time'].dt.tz_localize(None).astype('datetime64[ns]')\n",
    "    \n",
    "    df_m15 = pd.merge_asof(df_m15.sort_values('time'), h4_context.sort_values('time'), on='time', direction='backward')\n",
    "\n",
    "    if dxy_df is not None:\n",
    "        dxy_df['time'] = dxy_df['time'].dt.tz_localize(None).astype('datetime64[ns]')\n",
    "        dxy_subset = dxy_df[['time', 'dxy_rsi', 'dxy_ema_dist']]\n",
    "        df_m15 = pd.merge_asof(df_m15, dxy_subset.sort_values('time'), on='time', direction='backward')\n",
    "    else:\n",
    "        df_m15['dxy_rsi'] = 50.0 \n",
    "        df_m15['dxy_ema_dist'] = 0.0\n",
    "\n",
    "    df_m15.dropna(inplace=True)\n",
    "\n",
    "    # 4. FVG Detection\n",
    "    df_m15['prev_high'] = df_m15['high'].shift(2)\n",
    "    df_m15['prev_low'] = df_m15['low'].shift(2)\n",
    "    \n",
    "    df_m15['bull_gap'] = df_m15['low'] - df_m15['prev_high']\n",
    "    df_m15['is_bull_fvg'] = (df_m15['bull_gap'] > 0) & (df_m15['close'].shift(1) > df_m15['close'].shift(2))\n",
    "    df_m15['bull_fvg_size'] = np.where(df_m15['is_bull_fvg'], df_m15['bull_gap'] / pip_val, 0.0)\n",
    "    \n",
    "    df_m15['bear_gap'] = df_m15['prev_low'] - df_m15['high']\n",
    "    df_m15['is_bear_fvg'] = (df_m15['bear_gap'] > 0) & (df_m15['close'].shift(1) < df_m15['close'].shift(2))\n",
    "    df_m15['bear_fvg_size'] = np.where(df_m15['is_bear_fvg'], df_m15['bear_gap'] / pip_val, 0.0)\n",
    "    \n",
    "    df_m15['bull_fvg_atr_ratio'] = np.where(df_m15['is_bull_fvg'], df_m15['bull_gap'] / df_m15['atr_14'], 0.0)\n",
    "    df_m15['bear_fvg_atr_ratio'] = np.where(df_m15['is_bear_fvg'], df_m15['bear_gap'] / df_m15['atr_14'], 0.0)\n",
    "    \n",
    "    fvg_df = df_m15[(df_m15['is_bull_fvg']) | (df_m15['is_bear_fvg'])].copy()\n",
    "    \n",
    "    # 5. Unified Target Labeling (Brains 1, 2, and 3)\n",
    "    win_loss_labels, mfe_labels, regime_labels = [], [], []\n",
    "    sl_points = SL_PIPS * pip_val\n",
    "    tp_points = sl_points * RR_RATIO\n",
    "    invalidation_points = INVALIDATION_PIPS * pip_val\n",
    "    \n",
    "    times, highs, lows = df_m15['time'].values, df_m15['high'].values, df_m15['low'].values\n",
    "    \n",
    "    for _, row in fvg_df.iterrows():\n",
    "        future_idx = np.where(times > row['time'])[0]\n",
    "        if len(future_idx) == 0: \n",
    "            win_loss_labels.append(0); mfe_labels.append(0.0); regime_labels.append(0); continue\n",
    "            \n",
    "        max_search = min(len(future_idx), TIMEOUT_BARS)\n",
    "        f_highs, f_lows = highs[future_idx[:max_search]], lows[future_idx[:max_search]]\n",
    "        \n",
    "        outcome, max_excursion, max_adverse, mfe_resolved = -1, 0.0, 0.0, False\n",
    "        \n",
    "        if row['is_bull_fvg']:\n",
    "            entry = row['low']\n",
    "            sl, tp, ruin_price = entry - sl_points, entry + tp_points, entry - invalidation_points\n",
    "            for h, l in zip(f_highs, f_lows):\n",
    "                if not mfe_resolved:\n",
    "                    if h - entry > max_excursion: max_excursion = h - entry\n",
    "                    if entry - l > max_adverse: max_adverse = entry - l\n",
    "                    if l <= ruin_price: mfe_resolved = True\n",
    "                if outcome == -1:\n",
    "                    if l <= sl: outcome = 0\n",
    "                    elif h >= tp: outcome = 1\n",
    "        else:\n",
    "            entry = row['high']\n",
    "            sl, tp, ruin_price = entry + sl_points, entry - tp_points, entry + invalidation_points\n",
    "            for h, l in zip(f_highs, f_lows):\n",
    "                if not mfe_resolved:\n",
    "                    if entry - l > max_excursion: max_excursion = entry - l\n",
    "                    if h - entry > max_adverse: max_adverse = h - entry\n",
    "                    if h >= ruin_price: mfe_resolved = True\n",
    "                if outcome == -1:\n",
    "                    if h >= sl: outcome = 0\n",
    "                    elif l <= tp: outcome = 1\n",
    "                    \n",
    "        if outcome == -1: outcome = 0 # Timeout is a loss\n",
    "        \n",
    "        win_loss_labels.append(outcome)\n",
    "        mfe_labels.append(max_excursion / pip_val)\n",
    "        \n",
    "        # Regime: 1 (Clean Trend) if Winner AND Drawdown never exceeded 50% of SL. Else 0 (Chop).\n",
    "        if outcome == 1 and max_adverse <= (sl_points * 0.5): regime_labels.append(1)\n",
    "        else: regime_labels.append(0)\n",
    "        \n",
    "    fvg_df['target_win_loss'] = win_loss_labels\n",
    "    fvg_df['target_mfe_pips'] = mfe_labels\n",
    "    fvg_df['target_regime'] = regime_labels\n",
    "    \n",
    "    return fvg_df[['tick_volume', 'hour_of_day', 'rsi_14', 'atr_14', 'dist_to_ema', \n",
    "                   'bull_fvg_size', 'bear_fvg_size', 'bull_fvg_atr_ratio', 'bear_fvg_atr_ratio', \n",
    "                   'h4_rsi_14', 'h4_dist_to_ema', 'dxy_rsi', 'dxy_ema_dist', \n",
    "                   'target_win_loss', 'target_mfe_pips', 'target_regime']]\n",
    "\n",
    "def save_onnx_model(model, symbol, model_type, dims):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    initial_type = [(\"float_input\", FloatTensorType([None, dims]))]\n",
    "    \n",
    "    if model_type == \"mfe_regressor_v5\":\n",
    "        onx = convert_sklearn(model, initial_types=initial_type, target_opset={\"\": 12, \"ai.onnx.ml\": 3})\n",
    "    else:\n",
    "        onx = convert_sklearn(model, initial_types=initial_type, target_opset={\"\": 12, \"ai.onnx.ml\": 3}, options={type(model): {\"zipmap\": False}})\n",
    "        \n",
    "    # Standard name (MT5 reads this by default)\n",
    "    std_filename = f\"fvg_{model_type}_{symbol}.onnx\"\n",
    "    # Backup name (Avoids MT5 lock crashes)\n",
    "    ts_filename = f\"fvg_{model_type}_{symbol}_{timestamp}.onnx\"\n",
    "    \n",
    "    # For V4 backwards compatibility naming if needed based on the previous EA variables\n",
    "    if model_type == \"model_v4\":\n",
    "        std_filename = f\"fvg_model_{symbol}_v4.onnx\"\n",
    "    elif model_type == \"mfe_regressor_v5\":\n",
    "        std_filename = f\"fvg_mfe_regressor_{symbol}_v5.onnx\"\n",
    "    elif model_type == \"manager_v6\":\n",
    "        std_filename = f\"fvg_manager_{symbol}_v6.onnx\"\n",
    "    \n",
    "    with open(ts_filename, \"wb\") as f: f.write(onx.SerializeToString())\n",
    "    try:\n",
    "        with open(std_filename, \"wb\") as f: f.write(onx.SerializeToString())\n",
    "    except PermissionError:\n",
    "        print(f\"  [!] MT5 locked {std_filename}. Saved backup as {ts_filename}.\")\n",
    "\n",
    "def auto_train_pipeline():\n",
    "    if not mt5.initialize(): \n",
    "        print(\"MT5 Init Failed\"); return\n",
    "\n",
    "    utc_to = datetime.now(pytz.UTC)\n",
    "    utc_from = utc_to - timedelta(days=WINDOW_DAYS) \n",
    "    print(f\"Rolling Window: {utc_from.strftime('%Y-%m-%d')} to {utc_to.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # Process DXY Once\n",
    "    dxy_df = None\n",
    "    dxy_found = mt5.symbols_get(f\"*{DXY_SYMBOL}*\")\n",
    "    if dxy_found:\n",
    "        dxy_raw = fetch_data(dxy_found[0].name, mt5.TIMEFRAME_M15, utc_from, utc_to)\n",
    "        if dxy_raw is not None:\n",
    "            dxy_raw['dxy_ema_50'] = dxy_raw['close'].ewm(span=EMA_PERIOD, adjust=False).mean()\n",
    "            dxy_raw['dxy_ema_dist'] = dxy_raw['close'] - dxy_raw['dxy_ema_50']\n",
    "            dxy_raw['dxy_rsi'] = ta.rsi(dxy_raw['close'], length=14)\n",
    "            # FIXED: Strip timezone AND force nanosecond resolution for DXY stitching\n",
    "            dxy_raw['time'] = dxy_raw['time'].dt.tz_localize(None).astype('datetime64[ns]')\n",
    "            dxy_df = dxy_raw[['time', 'dxy_rsi', 'dxy_ema_dist']].dropna()\n",
    "\n",
    "    for sym in SYMBOLS:\n",
    "        df = build_features_and_labels(sym, dxy_df, utc_from, utc_to)\n",
    "        if df is None or len(df) < 50: \n",
    "            print(f\"Skipping {sym}, not enough data.\"); continue\n",
    "            \n",
    "        # Sample Weighting: Linearly weight recent data heavier to fight Concept Drift\n",
    "        weights = np.linspace(0.1, 1.0, len(df))\n",
    "        \n",
    "        X_13D = df.iloc[:, :13].values\n",
    "        X_9D = df.iloc[:, :9].values\n",
    "\n",
    "        # --- TRAIN BRAIN 1: WIN/LOSS CLASSIFIER ---\n",
    "        model_1 = xgb.XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05, random_state=42)\n",
    "        model_1.fit(X_13D, df['target_win_loss'].values, sample_weight=weights)\n",
    "        save_onnx_model(model_1, sym, \"model_v4\", 13)\n",
    "\n",
    "        # --- TRAIN BRAIN 2: MFE REGRESSOR ---\n",
    "        # Only train Regressor on setups that actually moved (> 2.0 pips)\n",
    "        mfe_mask = df['target_mfe_pips'] > 2.0\n",
    "        if mfe_mask.sum() > 20:\n",
    "            model_2 = xgb.XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.05, random_state=42)\n",
    "            model_2.fit(X_9D[mfe_mask], df.loc[mfe_mask, 'target_mfe_pips'].values, sample_weight=weights[mfe_mask])\n",
    "            save_onnx_model(model_2, sym, \"mfe_regressor_v5\", 9)\n",
    "\n",
    "        # --- TRAIN BRAIN 3: REGIME MANAGER ---\n",
    "        model_3 = xgb.XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05, random_state=42)\n",
    "        model_3.fit(X_13D, df['target_regime'].values, sample_weight=weights)\n",
    "        save_onnx_model(model_3, sym, \"manager_v6\", 13)\n",
    "        \n",
    "        print(f\"SUCCESS: Triple-Brain Models updated for {sym}.\")\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    auto_train_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
