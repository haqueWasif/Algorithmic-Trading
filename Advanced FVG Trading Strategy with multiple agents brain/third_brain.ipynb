{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7408ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Intermarket DXY Context...\n",
      "DXY loaded: DXYN rows=4023\n",
      "\n",
      "==================================================\n",
      " BUILDING BRAIN #3 (REGIME MANAGER) FOR EURUSD \n",
      "==================================================\n",
      "Bars=69586 | FVG setups=14584\n",
      "Calculating MAE/MFE Regimes... (fast)\n",
      "  labeled 500/14584\n",
      "  labeled 1000/14584\n",
      "  labeled 1500/14584\n",
      "  labeled 2000/14584\n",
      "  labeled 2500/14584\n",
      "  labeled 3000/14584\n",
      "  labeled 3500/14584\n",
      "  labeled 4000/14584\n",
      "  labeled 4500/14584\n",
      "  labeled 5000/14584\n",
      "  labeled 5500/14584\n",
      "  labeled 6000/14584\n",
      "  labeled 6500/14584\n",
      "  labeled 7000/14584\n",
      "  labeled 7500/14584\n",
      "  labeled 8000/14584\n",
      "  labeled 8500/14584\n",
      "  labeled 9000/14584\n",
      "  labeled 9500/14584\n",
      "  labeled 10000/14584\n",
      "  labeled 10500/14584\n",
      "  labeled 11000/14584\n",
      "  labeled 11500/14584\n",
      "  labeled 12000/14584\n",
      "  labeled 12500/14584\n",
      "  labeled 13000/14584\n",
      "  labeled 13500/14584\n",
      "  labeled 14000/14584\n",
      "  labeled 14500/14584\n",
      "Training Regime Classifier (time-safe)...\n",
      "OOS Accuracy: 77.07% | AUC: 0.609 | LogLoss: 0.5298 | Brier: 0.1737\n",
      "SUCCESS: Brain #3 Saved -> fvg_manager_EURUSD_v6.onnx\n",
      "\n",
      "==================================================\n",
      " BUILDING BRAIN #3 (REGIME MANAGER) FOR GBPUSD \n",
      "==================================================\n",
      "Bars=69591 | FVG setups=14760\n",
      "Calculating MAE/MFE Regimes... (fast)\n",
      "  labeled 500/14760\n",
      "  labeled 1000/14760\n",
      "  labeled 1500/14760\n",
      "  labeled 2000/14760\n",
      "  labeled 2500/14760\n",
      "  labeled 3000/14760\n",
      "  labeled 3500/14760\n",
      "  labeled 4000/14760\n",
      "  labeled 4500/14760\n",
      "  labeled 5000/14760\n",
      "  labeled 5500/14760\n",
      "  labeled 6000/14760\n",
      "  labeled 6500/14760\n",
      "  labeled 7000/14760\n",
      "  labeled 7500/14760\n",
      "  labeled 8000/14760\n",
      "  labeled 8500/14760\n",
      "  labeled 9000/14760\n",
      "  labeled 9500/14760\n",
      "  labeled 10000/14760\n",
      "  labeled 10500/14760\n",
      "  labeled 11000/14760\n",
      "  labeled 11500/14760\n",
      "  labeled 12000/14760\n",
      "  labeled 12500/14760\n",
      "  labeled 13000/14760\n",
      "  labeled 13500/14760\n",
      "  labeled 14000/14760\n",
      "  labeled 14500/14760\n",
      "Training Regime Classifier (time-safe)...\n",
      "OOS Accuracy: 79.78% | AUC: 0.617 | LogLoss: 0.4918 | Brier: 0.1574\n",
      "SUCCESS: Brain #3 Saved -> fvg_manager_GBPUSD_v6.onnx\n",
      "\n",
      "==================================================\n",
      " BUILDING BRAIN #3 (REGIME MANAGER) FOR USDJPY \n",
      "==================================================\n",
      "Bars=69592 | FVG setups=15483\n",
      "Calculating MAE/MFE Regimes... (fast)\n",
      "  labeled 500/15483\n",
      "  labeled 1000/15483\n",
      "  labeled 1500/15483\n",
      "  labeled 2000/15483\n",
      "  labeled 2500/15483\n",
      "  labeled 3000/15483\n",
      "  labeled 3500/15483\n",
      "  labeled 4000/15483\n",
      "  labeled 4500/15483\n",
      "  labeled 5000/15483\n",
      "  labeled 5500/15483\n",
      "  labeled 6000/15483\n",
      "  labeled 6500/15483\n",
      "  labeled 7000/15483\n",
      "  labeled 7500/15483\n",
      "  labeled 8000/15483\n",
      "  labeled 8500/15483\n",
      "  labeled 9000/15483\n",
      "  labeled 9500/15483\n",
      "  labeled 10000/15483\n",
      "  labeled 10500/15483\n",
      "  labeled 11000/15483\n",
      "  labeled 11500/15483\n",
      "  labeled 12000/15483\n",
      "  labeled 12500/15483\n",
      "  labeled 13000/15483\n",
      "  labeled 13500/15483\n",
      "  labeled 14000/15483\n",
      "  labeled 14500/15483\n",
      "  labeled 15000/15483\n",
      "Training Regime Classifier (time-safe)...\n",
      "OOS Accuracy: 82.53% | AUC: 0.607 | LogLoss: 0.4549 | Brier: 0.1416\n",
      "SUCCESS: Brain #3 Saved -> fvg_manager_USDJPY_v6.onnx\n"
     ]
    }
   ],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "import pandas_ta as ta\n",
    "import xgboost as xgb\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, brier_score_loss\n",
    "\n",
    "# ONNX Imports\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "\n",
    "update_registered_converter(\n",
    "    xgb.XGBClassifier, \"XGBoostXGBClassifier\",\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={\"nocl\": [True, False], \"zipmap\": [True, False, \"renamed\"]}\n",
    ")\n",
    "\n",
    "# --- USER CONFIG ---\n",
    "SYMBOLS = [\"EURUSD\", \"GBPUSD\", \"USDJPY\"]  # you can add more\n",
    "DXY_SYMBOL = \"DXY\"\n",
    "EMA_PERIOD = 50\n",
    "TIMEOUT_BARS = 48\n",
    "INVALIDATION_PIPS = 15.0\n",
    "\n",
    "# --- time-safe splits ---\n",
    "TEST_FRAC = 0.20   # last 20% test\n",
    "CAL_FRAC  = 0.10   # prior 10% calibration\n",
    "GAP_BARS  = 0      # optional embargo bars between splits\n",
    "\n",
    "FEATURES_13 = [\n",
    "    \"tick_volume\", \"hour_of_day\", \"rsi_14\", \"atr_14\",\n",
    "    \"dist_to_ema\", \"bull_fvg_size\", \"bear_fvg_size\",\n",
    "    \"bull_fvg_atr_ratio\", \"bear_fvg_atr_ratio\",\n",
    "    \"h4_rsi_14\", \"h4_dist_to_ema\", \"dxy_rsi\", \"dxy_ema_dist\"\n",
    "]\n",
    "\n",
    "def resolve_symbol(query: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Robust symbol resolver for MT5 brokers with suffixes.\n",
    "    - Prefers exact match (USDJPY)\n",
    "    - Otherwise uses wildcard (*USDJPY*) and chooses shortest name\n",
    "    - Ensures the chosen symbol is selected in Market Watch\n",
    "    \"\"\"\n",
    "    # Try exact first\n",
    "    exact = mt5.symbols_get(query)\n",
    "    if exact and len(exact) > 0:\n",
    "        name = exact[0].name\n",
    "        mt5.symbol_select(name, True)\n",
    "        return name\n",
    "\n",
    "    # Wildcard fallback\n",
    "    cands = mt5.symbols_get(f\"*{query}*\")\n",
    "    if not cands:\n",
    "        return None\n",
    "\n",
    "    # Prefer shortest symbol name containing query (often removes suffix noise)\n",
    "    cands = sorted(cands, key=lambda s: len(s.name))\n",
    "    name = cands[0].name\n",
    "    mt5.symbol_select(name, True)\n",
    "    return name\n",
    "\n",
    "def fetch_data(symbol, timeframe, utc_from, utc_to):\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, utc_from, utc_to)\n",
    "    if rates is None or len(rates) == 0:\n",
    "        return None\n",
    "    df = pd.DataFrame(rates)\n",
    "    # IMPORTANT: UTC-aware timestamps\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\", utc=True)\n",
    "    return df\n",
    "\n",
    "def make_splits(n: int, test_frac: float, cal_frac: float, gap: int):\n",
    "    \"\"\"\n",
    "    Time-safe split:\n",
    "      [ train .... ][ gap ][ calibrate ][ gap ][ test ]\n",
    "    \"\"\"\n",
    "    test_size = int(round(n * test_frac))\n",
    "    cal_size  = int(round(n * cal_frac))\n",
    "    train_end = n - (cal_size + test_size)\n",
    "\n",
    "    cal_start = train_end + gap\n",
    "    cal_end   = n - test_size\n",
    "    test_start = cal_end + gap\n",
    "\n",
    "    cal_start = min(max(cal_start, 0), n)\n",
    "    cal_end   = min(max(cal_end, cal_start), n)\n",
    "    test_start = min(max(test_start, cal_end), n)\n",
    "\n",
    "    train_idx = np.arange(0, max(train_end, 0))\n",
    "    cal_idx   = np.arange(cal_start, cal_end)\n",
    "    test_idx  = np.arange(test_start, n)\n",
    "    return train_idx, cal_idx, test_idx\n",
    "\n",
    "def generate_and_train_regime_model():\n",
    "    if not mt5.initialize():\n",
    "        print(\"MT5 initialize failed.\")\n",
    "        return\n",
    "\n",
    "    utc_from = datetime(2023, 5, 1, tzinfo=pytz.UTC)\n",
    "    utc_to   = datetime(2026, 2, 21, tzinfo=pytz.UTC)\n",
    "\n",
    "    # 1) Fetch DXY Context\n",
    "    print(\"Loading Intermarket DXY Context...\")\n",
    "    dxy_name = resolve_symbol(DXY_SYMBOL)\n",
    "    dxy_df = None\n",
    "\n",
    "    if dxy_name:\n",
    "        dxy_raw = fetch_data(dxy_name, mt5.TIMEFRAME_M15, utc_from, utc_to)\n",
    "        if dxy_raw is not None:\n",
    "            dxy_raw = dxy_raw.sort_values(\"time\").reset_index(drop=True)\n",
    "            dxy_raw[\"dxy_ema_50\"] = dxy_raw[\"close\"].ewm(span=EMA_PERIOD, adjust=False).mean()\n",
    "            dxy_raw[\"dxy_ema_dist\"] = dxy_raw[\"close\"] - dxy_raw[\"dxy_ema_50\"]\n",
    "            dxy_raw[\"dxy_rsi\"] = ta.rsi(dxy_raw[\"close\"], length=14)\n",
    "            dxy_df = dxy_raw[[\"time\", \"dxy_rsi\", \"dxy_ema_dist\"]].dropna().copy()\n",
    "            print(f\"DXY loaded: {dxy_name} rows={len(dxy_df)}\")\n",
    "        else:\n",
    "            print(f\"DXY symbol found ({dxy_name}) but no data. Using neutral defaults.\")\n",
    "    else:\n",
    "        print(\"DXY symbol not found. Using neutral defaults.\")\n",
    "\n",
    "    for sym in SYMBOLS:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\" BUILDING BRAIN #3 (REGIME MANAGER) FOR {sym} \")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        sym_name = resolve_symbol(sym)\n",
    "        if not sym_name:\n",
    "            print(f\"Symbol not found: {sym}\")\n",
    "            print(\"Candidates:\", [s.name for s in (mt5.symbols_get(f'*{sym}*') or [])][:30])\n",
    "            continue\n",
    "\n",
    "        df_m15 = fetch_data(sym_name, mt5.TIMEFRAME_M15, utc_from, utc_to)\n",
    "        df_h4  = fetch_data(sym_name, mt5.TIMEFRAME_H4,  utc_from, utc_to)\n",
    "        if df_m15 is None or df_h4 is None:\n",
    "            print(f\"Missing data for {sym_name}. Ensure symbol is selected + history downloaded.\")\n",
    "            continue\n",
    "\n",
    "        df_m15 = df_m15.sort_values(\"time\").reset_index(drop=True)\n",
    "        df_h4  = df_h4.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "        info = mt5.symbol_info(sym_name)\n",
    "        pip_val = info.point * (10.0 if info.digits in [3, 5] else 1.0)\n",
    "\n",
    "        # --- H4 context (NO +4 hours hack)\n",
    "        df_h4[\"h4_ema_50\"] = df_h4[\"close\"].ewm(span=EMA_PERIOD, adjust=False).mean()\n",
    "        df_h4[\"h4_dist_to_ema\"] = (df_h4[\"close\"] - df_h4[\"h4_ema_50\"]) / pip_val\n",
    "        df_h4[\"h4_rsi_14\"] = ta.rsi(df_h4[\"close\"], length=14)\n",
    "        h4_context = df_h4[[\"time\", \"h4_dist_to_ema\", \"h4_rsi_14\"]].dropna().copy()\n",
    "\n",
    "        # --- M15 indicators\n",
    "        df_m15[\"ema_50\"] = df_m15[\"close\"].ewm(span=EMA_PERIOD, adjust=False).mean()\n",
    "        df_m15[\"dist_to_ema\"] = (df_m15[\"close\"] - df_m15[\"ema_50\"]) / pip_val\n",
    "        df_m15[\"hour_of_day\"] = df_m15[\"time\"].dt.hour\n",
    "        df_m15[\"atr_14\"] = ta.atr(df_m15[\"high\"], df_m15[\"low\"], df_m15[\"close\"], length=14)\n",
    "        df_m15[\"rsi_14\"] = ta.rsi(df_m15[\"close\"], length=14)\n",
    "\n",
    "        # Merge H4 -> M15\n",
    "        df_m15 = pd.merge_asof(\n",
    "            df_m15.sort_values(\"time\"),\n",
    "            h4_context.sort_values(\"time\"),\n",
    "            on=\"time\",\n",
    "            direction=\"backward\"\n",
    "        )\n",
    "\n",
    "        # Merge DXY -> M15\n",
    "        if dxy_df is not None:\n",
    "            df_m15 = pd.merge_asof(\n",
    "                df_m15.sort_values(\"time\"),\n",
    "                dxy_df.sort_values(\"time\"),\n",
    "                on=\"time\",\n",
    "                direction=\"backward\"\n",
    "            )\n",
    "        else:\n",
    "            df_m15[\"dxy_rsi\"] = 50.0\n",
    "            df_m15[\"dxy_ema_dist\"] = 0.0\n",
    "\n",
    "        df_m15 = df_m15.dropna().reset_index(drop=True)\n",
    "\n",
    "        # --- FVG detection\n",
    "        df_m15[\"bull_gap\"] = df_m15[\"low\"] - df_m15[\"high\"].shift(2)\n",
    "        df_m15[\"is_bull_fvg\"] = (df_m15[\"bull_gap\"] > 0) & (df_m15[\"close\"].shift(1) > df_m15[\"close\"].shift(2))\n",
    "        df_m15[\"bear_gap\"] = df_m15[\"low\"].shift(2) - df_m15[\"high\"]\n",
    "        df_m15[\"is_bear_fvg\"] = (df_m15[\"bear_gap\"] > 0) & (df_m15[\"close\"].shift(1) < df_m15[\"close\"].shift(2))\n",
    "\n",
    "        df_m15[\"bull_fvg_size\"] = np.where(df_m15[\"is_bull_fvg\"], df_m15[\"bull_gap\"] / pip_val, 0.0)\n",
    "        df_m15[\"bear_fvg_size\"] = np.where(df_m15[\"is_bear_fvg\"], df_m15[\"bear_gap\"] / pip_val, 0.0)\n",
    "        df_m15[\"bull_fvg_atr_ratio\"] = np.where(df_m15[\"is_bull_fvg\"], df_m15[\"bull_gap\"] / df_m15[\"atr_14\"], 0.0)\n",
    "        df_m15[\"bear_fvg_atr_ratio\"] = np.where(df_m15[\"is_bear_fvg\"], df_m15[\"bear_gap\"] / df_m15[\"atr_14\"], 0.0)\n",
    "\n",
    "        fvg_df = df_m15[(df_m15[\"is_bull_fvg\"]) | (df_m15[\"is_bear_fvg\"])].copy()\n",
    "        if fvg_df.empty:\n",
    "            print(f\"No FVGs found for {sym}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Bars={len(df_m15)} | FVG setups={len(fvg_df)}\")\n",
    "\n",
    "        # =========================\n",
    "        # FAST REGIME LABELING FIX\n",
    "        # =========================\n",
    "        print(\"Calculating MAE/MFE Regimes... (fast)\")\n",
    "        regime_labels = []\n",
    "\n",
    "        # Keep original bar index for each FVG row\n",
    "        fvg_df = fvg_df.reset_index(drop=False).rename(columns={\"index\": \"bar_index\"})\n",
    "\n",
    "        highs = df_m15[\"high\"].to_numpy()\n",
    "        lows  = df_m15[\"low\"].to_numpy()\n",
    "\n",
    "        n_fvg = len(fvg_df)\n",
    "        for k, i in enumerate(fvg_df[\"bar_index\"].to_numpy(), start=1):\n",
    "            start = i + 1\n",
    "            if start >= len(df_m15):\n",
    "                regime_labels.append(0)\n",
    "                continue\n",
    "\n",
    "            end = min(start + TIMEOUT_BARS, len(df_m15))\n",
    "\n",
    "            is_bull = bool(df_m15.loc[i, \"is_bull_fvg\"])\n",
    "            mfe = 0.0\n",
    "            mae = 0.0\n",
    "\n",
    "            if is_bull:\n",
    "                entry = float(df_m15.loc[i, \"low\"])\n",
    "                for h, l in zip(highs[start:end], lows[start:end]):\n",
    "                    if (h - entry) > mfe: mfe = (h - entry)\n",
    "                    if (entry - l) > mae: mae = (entry - l)\n",
    "                    if (entry - l) >= (INVALIDATION_PIPS * pip_val):\n",
    "                        break\n",
    "            else:\n",
    "                entry = float(df_m15.loc[i, \"high\"])\n",
    "                for h, l in zip(highs[start:end], lows[start:end]):\n",
    "                    if (entry - l) > mfe: mfe = (entry - l)\n",
    "                    if (h - entry) > mae: mae = (h - entry)\n",
    "                    if (h - entry) >= (INVALIDATION_PIPS * pip_val):\n",
    "                        break\n",
    "\n",
    "            mfe_pips = mfe / pip_val\n",
    "            mae_pips = mae / pip_val\n",
    "            regime_labels.append(1 if (mfe_pips >= 15.0 and mae_pips <= 5.0) else 0)\n",
    "\n",
    "            if k % 500 == 0:\n",
    "                print(f\"  labeled {k}/{n_fvg}\")\n",
    "\n",
    "        fvg_df[\"target_regime\"] = regime_labels\n",
    "\n",
    "        # --- Training data\n",
    "        X = fvg_df[FEATURES_13].to_numpy(dtype=np.float32)\n",
    "        y = fvg_df[\"target_regime\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "        if y.sum() < 50:\n",
    "            print(f\"Not enough 'Clean Trend' setups found for {sym}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- time-safe train/cal/test split (no leakage)\n",
    "        train_idx, cal_idx, test_idx = make_splits(len(fvg_df), TEST_FRAC, CAL_FRAC, GAP_BARS)\n",
    "        if len(train_idx) < 200 or len(cal_idx) < 50 or len(test_idx) < 50:\n",
    "            print(f\"Split too small for {sym}: train={len(train_idx)}, cal={len(cal_idx)}, test={len(test_idx)}\")\n",
    "            continue\n",
    "\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_cal, y_cal     = X[cal_idx], y[cal_idx]\n",
    "        X_test, y_test   = X[test_idx], y[test_idx]\n",
    "\n",
    "        pos = int((y_train == 1).sum())\n",
    "        neg = int((y_train == 0).sum())\n",
    "        imbalance = (neg / pos) if pos > 0 else 1.0\n",
    "\n",
    "        print(\"Training Regime Classifier (time-safe)...\")\n",
    "        base_model = xgb.XGBClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            scale_pos_weight=imbalance,\n",
    "            random_state=42,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit base on TRAIN only\n",
    "        base_model.fit(X_train, y_train)\n",
    "\n",
    "        # Calibrate on later CAL slice (cv=\"prefit\" avoids shuffle/leak)\n",
    "        model = CalibratedClassifierCV(base_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "        model.fit(X_cal, y_cal)\n",
    "\n",
    "        # Evaluate on TEST (latest)\n",
    "        preds = model.predict(X_test)\n",
    "        proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        auc = roc_auc_score(y_test, proba) if len(np.unique(y_test)) > 1 else float(\"nan\")\n",
    "        ll  = log_loss(y_test, proba, labels=[0, 1])\n",
    "        brier = brier_score_loss(y_test, proba)\n",
    "\n",
    "        print(f\"OOS Accuracy: {acc:.2%} | AUC: {auc:.3f} | LogLoss: {ll:.4f} | Brier: {brier:.4f}\")\n",
    "\n",
    "        # Export Brain #3 ONNX\n",
    "        initial_type = [(\"float_input\", FloatTensorType([None, 13]))]\n",
    "        onx = convert_sklearn(\n",
    "            model,\n",
    "            initial_types=initial_type,\n",
    "            target_opset={\"\": 12, \"ai.onnx.ml\": 3},\n",
    "            options={type(model): {\"zipmap\": False}}\n",
    "        )\n",
    "\n",
    "        filename = f\"fvg_manager_{sym}_v6.onnx\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(onx.SerializeToString())\n",
    "        print(f\"SUCCESS: Brain #3 Saved -> {filename}\")\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_and_train_regime_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
